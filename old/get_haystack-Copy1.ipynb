{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import itertools\n",
    "from timeit import default_timer as timer\n",
    "from humanfriendly import format_timespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('admin.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_connect_mag import Session, Paper, PaperAuthorAffiliation, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447 references found in 0.01 seconds\n"
     ]
    }
   ],
   "source": [
    "# review paper on community detection in graphs\n",
    "review_paper_id = 2127048411\n",
    "start = timer()\n",
    "tbl = db.tables['PaperReferences']\n",
    "sq = tbl.select(tbl.c.Paper_ID==review_paper_id)\n",
    "r = db.engine.execute(sq).fetchall()\n",
    "reference_ids = [x['Paper_reference_ID'] for x in r]\n",
    "print(\"{} references found in {}\".format(len(reference_ids), format_timespan(timer()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jporteno/code/autoreview/venv/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "seed_papers, target_papers = train_test_split(r, train_size=50, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2157305458"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_papers[0]['Paper_reference_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_papers_2_degrees_out import get_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_papers = get_papers([x.Paper_reference_ID for x in seed_papers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a novel similarity based modularity function for graph partitioning'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = seed_papers[0]\n",
    "x['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a novel similarity based modularity function for graph partitioning'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_papers[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl1 = db.tables['Papers']\n",
    "tbl2 = db.tables['rank']\n",
    "j = tbl1.join(tbl2, tbl1.c.Paper_ID==tbl2.c.Paper_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = db.engine.execute(j.select(tbl1.c.Paper_ID==review_paper_id)).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(rng, np.random.RandomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = [pr.paper_cited for pr in review_paper.paperrefs_citing]\n",
    "print(len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_papers, target_papers = train_test_split(papers, train_size=50, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_papers = set(target_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "test_papers = set()\n",
    "c = Counter()\n",
    "cur_papers = list(train_papers)\n",
    "print(\"looping through {} papers\".format(len(cur_papers)))\n",
    "for i, paper in enumerate(cur_papers):\n",
    "    for p in [pr.paper_cited for pr in paper.paperrefs_citing]:\n",
    "        c[p.Paper_ID] += 1\n",
    "        test_papers.add(p)\n",
    "    for p in [pr.paper_citing for pr in paper.paperrefs_cited]:\n",
    "        c[p.Paper_ID] += 1\n",
    "        test_papers.add(p)\n",
    "    print(\"done with {} papers. len(test_papers)=={}\".format(i+1, len(test_papers)))\n",
    "print(format_timespan(timer()-start))\n",
    "print(len(test_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_papers.intersection(test_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_distance(n1, n2, sep=\":\"):\n",
    "    # https://en.wikipedia.org/wiki/Lowest_common_ancestor\n",
    "    # the distance from v to w can be computed as \n",
    "    # the distance from the root to v, plus the distance from \n",
    "    # the root to w, minus twice the distance from \n",
    "    # the root to their lowest common ancestor\n",
    "    v, w = [n.split(sep) for n in [n1, n2]]\n",
    "    distance_root_to_v = len(v)\n",
    "    distance_root_to_w = len(w)\n",
    "    \n",
    "    distance_root_to_lca = 0\n",
    "    for i in range(min(distance_root_to_v, distance_root_to_w)):\n",
    "        if v[i] == w[i]:\n",
    "            distance_root_to_lca += 1\n",
    "        else:\n",
    "            break\n",
    "    return distance_root_to_v + distance_root_to_w - (2*distance_root_to_lca)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_two_groups(g1, g2):\n",
    "    distances = []\n",
    "    for n1 in g1:\n",
    "        for n2 in g2:\n",
    "            if n1 == n2:\n",
    "                continue\n",
    "            distances.append(tree_distance(n1, n2))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_distances(g1, g2):\n",
    "    distances = distances_two_groups(g1, g2)\n",
    "    distances = pd.Series(distances)\n",
    "    return distances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "clusters = [p.cl for p in test_papers if p.cl]\n",
    "print(format_timespan(timer()-start))\n",
    "print(len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_distance(cl, cl_group):\n",
    "    distances = []\n",
    "    for x in cl_group:\n",
    "        distances.append(tree_distance(cl, x))\n",
    "    return sum(distances) / len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "rows = []\n",
    "train_cls = [p.cl for p in train_papers if p.cl]\n",
    "for p in test_papers:\n",
    "    pid = p.Paper_ID\n",
    "    title = p.title\n",
    "    ef = p.EF\n",
    "    cl = p.cl\n",
    "    if cl:\n",
    "        avg_distance_to_train = avg_distance(cl, train_cls)\n",
    "    else:\n",
    "        avg_distance_to_train = None\n",
    "    rows.append({\n",
    "        'Paper_ID': pid,\n",
    "        'title': title,\n",
    "        'EF': ef,\n",
    "        'cl': cl,\n",
    "        'avg_distance_to_train': avg_distance_to_train\n",
    "    })\n",
    "print(\"{} rows in {}\".format(len(rows), format_timespan(timer()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pids = set([p.Paper_ID for p in target_papers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df.Paper_ID.apply(lambda x: x in target_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('avg_distance_to_train').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.target==True].avg_distance_to_train.mean())\n",
    "print(df[df.target==False].avg_distance_to_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.target==True].EF.mean())\n",
    "print(df[df.target==False].EF.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(\"contains {} target papers\".format(df.target.sum()))\n",
    "print(\"\")\n",
    "ef_thresh = df.EF.min()\n",
    "print(\"removing papers with EF<={}\".format(ef_thresh))\n",
    "subset = df[df.EF>ef_thresh]\n",
    "print(len(subset))\n",
    "print(\"contains {} target papers\".format(subset.target.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset[subset.target==True].avg_distance_to_train.mean())\n",
    "print(subset[subset.target==False].avg_distance_to_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset[subset.target==True].EF.mean())\n",
    "print(subset[subset.target==False].EF.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.paperrefs_cited[2].Paper_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_addresses = [p.cl for p in papers]\n",
    "len(cluster_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_train_pairs = []\n",
    "train_clusters = [p.cl for p in train_papers]\n",
    "for n1, n2 in itertools.combinations(train_clusters, 2):\n",
    "    distances_train_pairs.append(tree_distance(n1, n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_train_pairs = pd.Series(distances_train_pairs)\n",
    "distances_train_pairs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_id = 137773608  # Nature\n",
    "nature_papers = session.query(Paper).filter_by(Journal_ID=journal_id).all()\n",
    "print(len(nature_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nature_papers = pd.Series(nature_papers)\n",
    "nature_sample = nature_papers.sample(n=200, random_state=999)\n",
    "nature_samples_clusters = [p.cl for p in nature_sample if p.cl]\n",
    "len(nature_samples_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_review_papers_distances = distances_two_groups(cluster_addresses, cluster_addresses)\n",
    "within_review_papers_distances = pd.Series(within_review_papers_distances)\n",
    "within_review_papers_distances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_review_to_nature = distances_two_groups(cluster_addresses, nature_samples_clusters)\n",
    "distances_review_to_nature = pd.Series(distances_review_to_nature)\n",
    "distances_review_to_nature.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paas = session.query(PaperAuthorAffiliation).filter_by(Author_ID=2151641964).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grinstaff_papers = [paa.paper for paa in paas if paa.paper]\n",
    "print(len(grinstaff_papers))\n",
    "grinstaff_clusters = [p.cl for p in grinstaff_papers if p.cl]\n",
    "print(len(grinstaff_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_distances(cluster_addresses, grinstaff_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "rosvall_paas = session.query(PaperAuthorAffiliation).filter_by(Author_ID=1999253335).all()\n",
    "print(\"{} records in {}\".format(len(rosvall_paas), format_timespan(timer()-start)))\n",
    "rosvall_papers = [paa.paper for paa in rosvall_paas if paa.paper]\n",
    "print(\"{} papers\".format(len(rosvall_papers)))\n",
    "rosvall_clusters = [p.cl for p in rosvall_papers if p.cl]\n",
    "print(\"{} clusters\".format(len(rosvall_clusters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_distances(cluster_addresses, rosvall_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoreview_venv",
   "language": "python",
   "name": "autoreview_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
